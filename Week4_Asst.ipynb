{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Numpy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for reading and displaying images, import imread and matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for creating validation set, import train_test_split; understand how the function works\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model, import accuracy_score from sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import necessary PyTorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import dataset from pytorch vision - Fashion MNIST\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and use dataloader to send the data in batches.\n",
    "# Convert data to tensor and normalise it.\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress','Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle-boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set :  60000\n",
      "Image Size :  torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of training set : \",len(trainset))\n",
    "image,label=trainset[0]\n",
    "print(\"Image Size : \",image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shirt Pullover   Bag Dress\n"
     ]
    }
   ],
   "source": [
    "# Visualise some random images from the datset. Check the shape of tensors to get a better understanding of the dataset.\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network architecture(model) using a class.\n",
    "# Use conv2d layers, activation function after each such layer, use Batchnorm and Maxpooling. Play with these parameters,\n",
    "# layers and things like kernel size, stride etc and see how it affects your results.\n",
    "# Finally use a linear layer in the end\n",
    "# Define the forward pass\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 4)\n",
    "        self.fc2 = nn.Linear(4,30* 84)\n",
    "        self.fc3 = nn.Linear(30*84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network architecture(model) using a class.\n",
    "# Use conv2d layers, activation function after each such layer, use Batchnorm and Maxpooling. Play with these parameters,\n",
    "# layers and things like kernel size, stride etc and see how it affects your results.\n",
    "# Finally use a linear layer in the end\n",
    "# Define the forward pass\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below cells are training the model(takes so much time) and are saved in the respective path..Better not to run..Directly move to the testing part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] CELloss: 1.047\n",
      "[1,  4000] CELloss: 0.584\n",
      "[1,  6000] CELloss: 0.514\n",
      "[1,  8000] CELloss: 0.462\n",
      "[1, 10000] CELloss: 0.426\n",
      "[1, 12000] CELloss: 0.393\n",
      "[1, 14000] CELloss: 0.383\n",
      "[2,  2000] CELloss: 0.342\n",
      "[2,  4000] CELloss: 0.328\n",
      "[2,  6000] CELloss: 0.337\n",
      "[2,  8000] CELloss: 0.316\n",
      "[2, 10000] CELloss: 0.314\n",
      "[2, 12000] CELloss: 0.311\n",
      "[2, 14000] CELloss: 0.305\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#************************************ SECOND MODEL *************************************************\n",
    "#******************************SGD as OPTIMIZER && CROSS ENTROPY as LOSS Func********************************\n",
    "# Define training the model\n",
    "net = Net1()\n",
    "# defining the optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# For each epoch and in each batch:\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute the model output\n",
    "        outputs = net(inputs)\n",
    "        # calculate loss; store and print them if you wish to print and see if the loss is decreasing.\n",
    "        CELloss = criterion(outputs, labels)\n",
    "        # propagate loss backwards\n",
    "        CELloss.backward()\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += CELloss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] CELloss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the trained model in the PATH\n",
    "PATH = './SGD_CEL_F-MNIST_net1.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] CELloss: 0.660\n",
      "[1,  4000] CELloss: 0.455\n",
      "[1,  6000] CELloss: 0.399\n",
      "[1,  8000] CELloss: 0.354\n",
      "[1, 10000] CELloss: 0.363\n",
      "[1, 12000] CELloss: 0.319\n",
      "[1, 14000] CELloss: 0.330\n",
      "[2,  2000] CELloss: 0.289\n",
      "[2,  4000] CELloss: 0.294\n",
      "[2,  6000] CELloss: 0.305\n",
      "[2,  8000] CELloss: 0.286\n",
      "[2, 10000] CELloss: 0.284\n",
      "[2, 12000] CELloss: 0.288\n",
      "[2, 14000] CELloss: 0.305\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#************************************ SECOND MODEL *************************************************\n",
    "#******************************ADAM as OPTIMIZER && CROSS ENTROPY as LOSS Func********************************\n",
    "# Define training the model\n",
    "net = Net1()\n",
    "# defining the optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# For each epoch and in each batch:\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute the model output\n",
    "        outputs = net(inputs)\n",
    "        # calculate loss; store and print them if you wish to print and see if the loss is decreasing.\n",
    "        CELloss = criterion(outputs, labels)\n",
    "        # propagate loss backwards\n",
    "        CELloss.backward()\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += CELloss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] CELloss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the trained model in the PATH\n",
    "PATH = './Adam_CEL_F-MNIST_net1.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] CELloss: 1.140\n",
      "[1,  4000] CELloss: 0.681\n",
      "[1,  6000] CELloss: 0.616\n",
      "[1,  8000] CELloss: 0.586\n",
      "[1, 10000] CELloss: 0.544\n",
      "[1, 12000] CELloss: 0.520\n",
      "[1, 14000] CELloss: 0.528\n",
      "[2,  2000] CELloss: 0.491\n",
      "[2,  4000] CELloss: 0.512\n",
      "[2,  6000] CELloss: 0.485\n",
      "[2,  8000] CELloss: 0.495\n",
      "[2, 10000] CELloss: 0.486\n",
      "[2, 12000] CELloss: 0.477\n",
      "[2, 14000] CELloss: 0.487\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#******************************SGD as OPTIMIZER && CROSS ENTROPY as LOSS Func********************************\n",
    "# Define training the model\n",
    "net = Net()\n",
    "# defining the optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# For each epoch and in each batch:\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute the model output\n",
    "        outputs = net(inputs)\n",
    "        # calculate loss; store and print them if you wish to print and see if the loss is decreasing.\n",
    "        CELloss = criterion(outputs, labels)\n",
    "        # propagate loss backwards\n",
    "        CELloss.backward()\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += CELloss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] CELloss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the trained model in the PATH\n",
    "PATH = './SGD_CEL_F-MNIST_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] CTCloss: 1.138\n",
      "[1,  4000] CTCloss: 0.682\n",
      "[1,  6000] CTCloss: 0.619\n",
      "[1,  8000] CTCloss: 0.579\n",
      "[1, 10000] CTCloss: 0.548\n",
      "[1, 12000] CTCloss: 0.520\n",
      "[1, 14000] CTCloss: 0.516\n",
      "[2,  2000] CTCloss: 0.494\n",
      "[2,  4000] CTCloss: 0.507\n",
      "[2,  6000] CTCloss: 0.494\n",
      "[2,  8000] CTCloss: 0.482\n",
      "[2, 10000] CTCloss: 0.496\n",
      "[2, 12000] CTCloss: 0.471\n",
      "[2, 14000] CTCloss: 0.472\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#******************************SGD as OPTIMIZER && Connectionist Temporal Classification as LOSS Func********************************\n",
    "# Define training the model\n",
    "net = Net()\n",
    "# defining the optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "# defining the loss function\n",
    "criterian = nn.CTCLoss()\n",
    "# For each epoch and in each batch:\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute the model output\n",
    "        outputs = net(inputs)\n",
    "        # calculate loss; store and print them if you wish to print and see if the loss is decreasing.\n",
    "        CTCloss = criterion(outputs, labels)\n",
    "        # propagate loss backwards\n",
    "        CTCloss.backward()\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += CTCloss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] CTCloss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the trained model in the PATH\n",
    "PATH = './SGD_CTC_F-MNIST_net.pth'\n",
    "torch.save(net.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] CELloss: 1.615\n",
      "[1,  4000] CELloss: 0.825\n",
      "[1,  6000] CELloss: 0.740\n",
      "[1,  8000] CELloss: 0.684\n",
      "[1, 10000] CELloss: 0.657\n",
      "[1, 12000] CELloss: 0.626\n",
      "[1, 14000] CELloss: 0.637\n",
      "[2,  2000] CELloss: 0.608\n",
      "[2,  4000] CELloss: 0.581\n",
      "[2,  6000] CELloss: 0.528\n",
      "[2,  8000] CELloss: 0.534\n",
      "[2, 10000] CELloss: 0.514\n",
      "[2, 12000] CELloss: 0.498\n",
      "[2, 14000] CELloss: 0.517\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#******************************ADAM as OPTIMIZER && CROSS ENTROPY as LOSS Func********************************\n",
    "# Define training the model\n",
    "net = Net()\n",
    "# defining the optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# For each epoch and in each batch:\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute the model output\n",
    "        outputs = net(inputs)\n",
    "        # calculate loss; store and print them if you wish to print and see if the loss is decreasing.\n",
    "        CELloss = criterion(outputs, labels)\n",
    "        # propagate loss backwards\n",
    "        CELloss.backward()\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += CELloss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] CELloss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the trained model in the PATH\n",
    "PATH = './Adam_CEL_F-MNIST_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] CTCloss: 0.973\n",
      "[1,  4000] CTCloss: 0.659\n",
      "[1,  6000] CTCloss: 0.601\n",
      "[1,  8000] CTCloss: 0.552\n",
      "[1, 10000] CTCloss: 0.543\n",
      "[1, 12000] CTCloss: 0.548\n",
      "[1, 14000] CTCloss: 0.521\n",
      "[2,  2000] CTCloss: 0.509\n",
      "[2,  4000] CTCloss: 0.475\n",
      "[2,  6000] CTCloss: 0.456\n",
      "[2,  8000] CTCloss: 0.500\n",
      "[2, 10000] CTCloss: 0.465\n",
      "[2, 12000] CTCloss: 0.480\n",
      "[2, 14000] CTCloss: 0.447\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#******************************ADAM as OPTIMIZER && Connectionist Temporal Classification as LOSS Func********************************\n",
    "# Define training the model\n",
    "net = Net()\n",
    "# defining the optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# defining the loss function\n",
    "criterian = nn.CTCLoss()\n",
    "# For each epoch and in each batch:\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute the model output\n",
    "        outputs = net(inputs)\n",
    "        # calculate loss; store and print them if you wish to print and see if the loss is decreasing.\n",
    "        CTCloss = criterion(outputs, labels)\n",
    "        # propagate loss backwards\n",
    "        CTCloss.backward()\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += CTCloss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] CTCloss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the trained model in the PATH\n",
    "PATH = './Adam_CTC_F-MNIST_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] CELloss: 0.667\n",
      "[1,  4000] CELloss: 0.451\n",
      "[1,  6000] CELloss: 0.391\n",
      "[1,  8000] CELloss: 0.371\n",
      "[1, 10000] CELloss: 0.361\n",
      "[1, 12000] CELloss: 0.330\n",
      "[1, 14000] CELloss: 0.345\n",
      "[2,  2000] CELloss: 0.306\n",
      "[2,  4000] CELloss: 0.293\n",
      "[2,  6000] CELloss: 0.293\n",
      "[2,  8000] CELloss: 0.291\n",
      "[2, 10000] CELloss: 0.283\n",
      "[2, 12000] CELloss: 0.291\n",
      "[2, 14000] CELloss: 0.276\n",
      "[3,  2000] CELloss: 0.261\n",
      "[3,  4000] CELloss: 0.258\n",
      "[3,  6000] CELloss: 0.247\n",
      "[3,  8000] CELloss: 0.260\n",
      "[3, 10000] CELloss: 0.267\n",
      "[3, 12000] CELloss: 0.266\n",
      "[3, 14000] CELloss: 0.259\n",
      "[4,  2000] CELloss: 0.224\n",
      "[4,  4000] CELloss: 0.239\n",
      "[4,  6000] CELloss: 0.258\n",
      "[4,  8000] CELloss: 0.238\n",
      "[4, 10000] CELloss: 0.258\n",
      "[4, 12000] CELloss: 0.243\n",
      "[4, 14000] CELloss: 0.228\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#************************************ SECOND MODEL with increase in epochs *************************************************\n",
    "#******************************ADAM as OPTIMIZER && CROSS ENTROPY as LOSS Func********************************\n",
    "# Define training the model\n",
    "net = Net1()\n",
    "# defining the optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# For each epoch and in each batch:\n",
    "for epoch in range(4):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute the model output\n",
    "        outputs = net(inputs)\n",
    "        # calculate loss; store and print them if you wish to print and see if the loss is decreasing.\n",
    "        CELloss = criterion(outputs, labels)\n",
    "        # propagate loss backwards\n",
    "        CELloss.backward()\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += CELloss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] CELloss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the trained model in the PATH\n",
    "PATH = './Adam_CEL_F-MNIST_net1_ep4.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here Testing of all the trained model loaded from their path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************* SGD AS OPTIMIZER && CROSS ENTROPY AS LOSS FUNC ********************\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "Accuracy(USING SKLEARN) of the network on the 10000 test images: % 84.82\n"
     ]
    }
   ],
   "source": [
    "#******************************SGD as OPTIMIZER && CROSS ENTROPY as LOSS Func********************************\n",
    "PATH = './SGD_CEL_F-MNIST_net.pth'\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))  \n",
    "\n",
    "# Evaluate model on test set. This is done in the same way as for training but only till calculating output.\n",
    "correct = 0\n",
    "total = 0\n",
    "prediction=[]\n",
    "Actual=[]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction.extend(predicted)\n",
    "        Actual.extend(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "\n",
    " \n",
    "#Then,convert output from tensor to numpy format.\n",
    "# convert to class labels\n",
    "# store the predictions\n",
    "prediction=np.array(prediction)\n",
    "Actual=np.array(Actual)\n",
    "\n",
    "print(\"******************* SGD AS OPTIMIZER && CROSS ENTROPY AS LOSS FUNC ********************\")\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "# calculate accuracy of model\n",
    "print('Accuracy(USING SKLEARN) of the network on the 10000 test images: %' ,100*accuracy_score(Actual,prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************* SGD AS OPTIMIZER && CTC AS LOSS FUNC ********************\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "Accuracy(USING SKLEARN) of the network on the 10000 test images: % 84.39999999999999\n"
     ]
    }
   ],
   "source": [
    "#******************************SGD as OPTIMIZER && Connectionist Temporal Classification as LOSS Func ********************************\n",
    "PATH = './SGD_CTC_F-MNIST_net.pth'\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))  \n",
    "\n",
    "# Evaluate model on test set. This is done in the same way as for training but only till calculating output.\n",
    "correct = 0\n",
    "total = 0\n",
    "prediction=[]\n",
    "Actual=[]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction.extend(predicted)\n",
    "        Actual.extend(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "\n",
    " \n",
    "#Then,convert output from tensor to numpy format.\n",
    "# convert to class labels\n",
    "# store the predictions\n",
    "prediction=np.array(prediction)\n",
    "Actual=np.array(Actual)\n",
    "\n",
    "print(\"******************* SGD AS OPTIMIZER && CTC AS LOSS FUNC ********************\")\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "# calculate accuracy of model\n",
    "print('Accuracy(USING SKLEARN) of the network on the 10000 test images: %' ,100*accuracy_score(Actual,prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************* ADAM AS OPTIMIZER && CROSS ENTROPY AS LOSS FUNC ********************\n",
      "Accuracy of the network on the 10000 test images: 80 %\n",
      "Accuracy(USING SKLEARN) of the network on the 10000 test images: % 80.78999999999999\n"
     ]
    }
   ],
   "source": [
    "#****************************** ADAM as OPTIMIZER && CROSS ENTROPY as LOSS Func********************************\n",
    "PATH = './Adam_CEL_F-MNIST_net.pth'\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))  \n",
    "\n",
    "# Evaluate model on test set. This is done in the same way as for training but only till calculating output.\n",
    "correct = 0\n",
    "total = 0\n",
    "prediction=[]\n",
    "Actual=[]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction.extend(predicted)\n",
    "        Actual.extend(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "\n",
    " \n",
    "#Then,convert output from tensor to numpy format.\n",
    "# convert to class labels\n",
    "# store the predictions\n",
    "prediction=np.array(prediction)\n",
    "Actual=np.array(Actual)\n",
    "\n",
    "print(\"******************* ADAM AS OPTIMIZER && CROSS ENTROPY AS LOSS FUNC ********************\")\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "# calculate accuracy of model\n",
    "print('Accuracy(USING SKLEARN) of the network on the 10000 test images: %' ,100*accuracy_score(Actual,prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************* ADAM AS OPTIMIZER && CTC AS LOSS FUNC ********************\n",
      "Accuracy of the network on the 10000 test images: 82 %\n",
      "Accuracy(USING SKLEARN) of the network on the 10000 test images: % 82.37\n"
     ]
    }
   ],
   "source": [
    "#****************************** Adam as OPTIMIZER && Connectionist Temporal Classification as LOSS Func ********************************\n",
    "PATH = './Adam_CTC_F-MNIST_net.pth'\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))  \n",
    "\n",
    "# Evaluate model on test set. This is done in the same way as for training but only till calculating output.\n",
    "correct = 0\n",
    "total = 0\n",
    "prediction=[]\n",
    "Actual=[]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction.extend(predicted)\n",
    "        Actual.extend(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "\n",
    " \n",
    "#Then,convert output from tensor to numpy format.\n",
    "# convert to class labels\n",
    "# store the predictions\n",
    "prediction=np.array(prediction)\n",
    "Actual=np.array(Actual)\n",
    "\n",
    "print(\"******************* ADAM AS OPTIMIZER && CTC AS LOSS FUNC ********************\")\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "# calculate accuracy of model\n",
    "print('Accuracy(USING SKLEARN) of the network on the 10000 test images: %' ,100*accuracy_score(Actual,prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************** SECOND MODEL *****************************************\n",
      "******************* SGD AS OPTIMIZER && CROSS ENTROPY AS LOSS FUNC ********************\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "Accuracy(USING SKLEARN) of the network on the 10000 test images: % 88.82\n"
     ]
    }
   ],
   "source": [
    "#***************************************** SECOND MODEL ********************************************\n",
    "#******************************SGD as OPTIMIZER && CROSS ENTROPY as LOSS Func********************************\n",
    "PATH = './SGD_CEL_F-MNIST_net1.pth'\n",
    "net = Net1()\n",
    "net.load_state_dict(torch.load(PATH))  \n",
    "\n",
    "# Evaluate model on test set. This is done in the same way as for training but only till calculating output.\n",
    "correct = 0\n",
    "total = 0\n",
    "prediction=[]\n",
    "Actual=[]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction.extend(predicted)\n",
    "        Actual.extend(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "\n",
    " \n",
    "#Then,convert output from tensor to numpy format.\n",
    "# convert to class labels\n",
    "# store the predictions\n",
    "prediction=np.array(prediction)\n",
    "Actual=np.array(Actual)\n",
    "print(\"******************************** SECOND MODEL *****************************************\")\n",
    "\n",
    "print(\"******************* SGD AS OPTIMIZER && CROSS ENTROPY AS LOSS FUNC ********************\")\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "# calculate accuracy of model\n",
    "print('Accuracy(USING SKLEARN) of the network on the 10000 test images: %' ,100*accuracy_score(Actual,prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** SECOND MODEL **********************************\n",
      "******************* ADAM AS OPTIMIZER && CEL AS LOSS FUNC ********************\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "Accuracy(USING SKLEARN) of the network on the 10000 test images: % 89.48\n"
     ]
    }
   ],
   "source": [
    "#***************************************** SECOND MODEL ********************************************\n",
    "#****************************** Adam as OPTIMIZER && Cross Entropy as LOSS Func ********************************\n",
    "PATH = './Adam_CEL_F-MNIST_net1.pth'\n",
    "net = Net1()\n",
    "net.load_state_dict(torch.load(PATH))  \n",
    "\n",
    "# Evaluate model on test set. This is done in the same way as for training but only till calculating output.\n",
    "correct = 0\n",
    "total = 0\n",
    "prediction=[]\n",
    "Actual=[]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction.extend(predicted)\n",
    "        Actual.extend(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "\n",
    " \n",
    "#Then,convert output from tensor to numpy format.\n",
    "# convert to class labels\n",
    "# store the predictions\n",
    "prediction=np.array(prediction)\n",
    "Actual=np.array(Actual)\n",
    "\n",
    "print(\"****************************** SECOND MODEL **********************************\")\n",
    "\n",
    "print(\"******************* ADAM AS OPTIMIZER && CEL AS LOSS FUNC ********************\")\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "# calculate accuracy of model\n",
    "print('Accuracy(USING SKLEARN) of the network on the 10000 test images: %' ,100*accuracy_score(Actual,prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** SECOND MODEL **********************************\n",
      "******************* ADAM AS OPTIMIZER && CEL AS LOSS FUNC ********************\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "Accuracy(USING SKLEARN) of the network on the 10000 test images: % 89.92\n"
     ]
    }
   ],
   "source": [
    "#***************************************** SECOND MODEL ********************************************\n",
    "#****************************** Adam as OPTIMIZER && Cross Entropy as LOSS Func ********************************\n",
    "PATH = './Adam_CEL_F-MNIST_net1_ep4.pth'\n",
    "net = Net1()\n",
    "net.load_state_dict(torch.load(PATH))  \n",
    "\n",
    "# Evaluate model on test set. This is done in the same way as for training but only till calculating output.\n",
    "correct = 0\n",
    "total = 0\n",
    "prediction=[]\n",
    "Actual=[]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction.extend(predicted)\n",
    "        Actual.extend(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "\n",
    " \n",
    "#Then,convert output from tensor to numpy format.\n",
    "# convert to class labels\n",
    "# store the predictions\n",
    "prediction=np.array(prediction)\n",
    "Actual=np.array(Actual)\n",
    "\n",
    "print(\"****************************** SECOND MODEL **********************************\")\n",
    "\n",
    "print(\"******************* ADAM AS OPTIMIZER && CEL AS LOSS FUNC ********************\")\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "# calculate accuracy of model\n",
    "print('Accuracy(USING SKLEARN) of the network on the 10000 test images: %' ,100*accuracy_score(Actual,prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  Try to improve accuracy by changing parameters, optimizer, loss functions, epochs etc\n",
    "  and explain your observations in a text file in the Github repository.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  Ankle-boot Pullover Trouser Trouser\n",
      "Predicted:  Ankle-boot Pullover Trouser Trouser\n"
     ]
    }
   ],
   "source": [
    "# check predictions by printing the output image for random test inputs.\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "outputs=net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
